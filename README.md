# Analyse de Sentiment sur des Commentaires Textuels

Projet rÃ©alisÃ© dans le cadre du cours dâ€™informatique dÃ©cisionnel de lâ€™organisation **INFO-DECISIO**.  
Lâ€™objectifâ€¯: construire un pipeline robuste pour prÃ©dire le **sentiment** (positif / neutre / nÃ©gatif) de commentaires issus des rÃ©seaux sociaux, en sâ€™appuyant sur les techniques modernes dâ€™analyse de donnÃ©es et de machine learning.

---

## ğŸ“‹ Contexte & Objectifs

Lâ€™analyse automatique des opinions (sentiment analysis) est cruciale pour de nombreux mÃ©tiersâ€¯: veille, rÃ©putation, marketing, etc.  
Ce projet vise Ã â€¯:

- DÃ©ployer un pipeline completâ€¯: exploration, nettoyage, vectorisation, modÃ©lisation, Ã©valuation et sauvegarde.
- Rendre le processus reproductible et facilement intÃ©grable (prÃ©paration Ã  une application web).
- SÃ©lectionner le modÃ¨le le plus performant et justifier ce choix selon les rÃ©sultats obtenus.

---

## ğŸ“¦ DonnÃ©es

- **Source**â€¯: [Kaggle â€“ Sentiment Analysis EDA and Prediction (input)](https://www.kaggle.com/code/alokkumar2507/sentiment-analysis-eda-and-prediction/input)
- **Fichier**â€¯: `data/sentiment_analysis.csv`
  > **NBâ€¯:** TÃ©lÃ©charger manuellement le jeu de donnÃ©es sur Kaggle et le placer dans le dossier `data/` Ã  la racine du projet.

---

## ğŸ—‚ï¸ Structure du projet

- `notebooks/1_data_exploration.ipynb`â€¯: Analyse exploratoire (EDA)
- `notebooks/2_data_preprocessing.ipynb`â€¯: Nettoyage et vectorisation des textes
- `notebooks/3_model_training_evaluation.ipynb`â€¯: ModÃ©lisation et Ã©valuation
- `data/`â€¯: Contient le dataset
- `models/`â€¯: Contient les modÃ¨les et vectoriseurs sauvegardÃ©s
- `README.md`â€¯: Ce document

---

## ğŸš¦ Pipeline du projet

### 1. Analyse exploratoire des donnÃ©es (EDA)

**Objectifs**â€¯:
- Comprendre la structure et la qualitÃ© du dataset
- Analyser la distribution des sentiments
- Identifier les valeurs manquantes
- Explorer les caractÃ©ristiques textuelles (longueur, mots frÃ©quents)
- Visualiser via graphiques et nuages de mots

---

### 2. PrÃ©traitement des donnÃ©es textuelles

**Ã‰tapes clÃ©s**â€¯:
- **Nettoyage**â€¯: conversion en minuscules, suppression des URLs, mentions, hashtags, chiffres et ponctuations.
- **Tokenisation & Lemmatisation** (NLTK)â€¯: segmentation en mots, suppression des stopwords anglais, rÃ©duction Ã  la racine.
- **Vectorisation**â€¯: transformation en vecteurs numÃ©riques via **TF-IDF** (maximum 5000 termes, min_df=5, max_df=0.8).
- **Split train/test**â€¯: division 80/20, stratification sur la cible pour respecter la rÃ©partition des classes.

**Exemple de distribution aprÃ¨s split**â€¯:
- **Train**â€¯: neutral ~40%, positive ~33%, negative ~27%
- **Test**â€¯: proportions similaires

---

### 3. ModÃ©lisation et Ã©valuation

**ModÃ¨les testÃ©s**â€¯:
- **Naive Bayes Multinomial**â€¯: simple et efficace pour du texte
- **RÃ©gression Logistique**â€¯: baseline linÃ©aire interprÃ©table
- **SVM linÃ©aire (LinearSVC)**â€¯: performant en haute dimension (texte vectorisÃ©)

**MÃ©triques utilisÃ©es**â€¯:
- Accuracy
- Precision, Recall, F1-score (moyenne pondÃ©rÃ©e & par classe)
- Matrice de confusion dÃ©taillÃ©e
- Analyse du dÃ©sÃ©quilibre entre classes

**Extrait de rÃ©sultats (test set)**â€¯:

| ModÃ¨le                  | Accuracy | Precision (weighted) | Recall (weighted) | F1 (weighted) |
|-------------------------|----------|----------------------|-------------------|---------------|
| Naive Bayes Multinomial | 0.6200   | 0.6359               | 0.6200            | 0.6124        |
| RÃ©gression Logistique   | 0.6400   | 0.6601               | 0.6400            | 0.6309        |
| Linear SVM              | **0.6500**   | 0.6493               | **0.6500**            | **0.6430**        |

> - **Linear SVM** > meilleure accuracy & F1 global.
> - Tous les modÃ¨les ont du mal sur la classe "negative", mais Linear SVM Ã©quilibre mieux les prÃ©dictions et diminue le biais sur la classe "neutral".
> - La RÃ©gression Logistique est trÃ¨s prÃ©cise sur "positive" mais plus biaisÃ©e vers "neutral".

---

### 4. SÃ©lection et justification du modÃ¨le final

AprÃ¨s analyseâ€¯:

- **Linear SVM** est retenu pourâ€¯:
  - Sa meilleure performance globale (accuracy & F1 pondÃ©rÃ©)
  - Son rappel "negative" lÃ©gÃ¨rement meilleur
  - Moins de biais vers la classe majoritaire
  - RapiditÃ© et compacitÃ© pour une intÃ©gration web future

---

### 5. Sauvegarde et perspectives dâ€™intÃ©gration

- **Le modÃ¨le SVM entraÃ®nÃ©** et le **vectoriseur TF-IDF** sont sauvegardÃ©s dans `models/` (`linear_svc_model.pkl`, `tfidf_vectorizer.pkl`) via `pickle` pour un futur dÃ©ploiement (API ou app web).
- **Prochaines pistes**â€¯:
  - Tunings dâ€™hyperparamÃ¨tres
  - Tests avec dâ€™autres mÃ©thodes de vectorisation (embeddings)
  - ExpÃ©rimentations avec des architectures avancÃ©es (deep learning)

---

## âš™ï¸ PrÃ©requis & installation

- Python â‰¥ 3.7
- Jupyter Notebook
- BibliothÃ¨ques principalesâ€¯:  
  `pandas`, `numpy`, `matplotlib`, `seaborn`, `scikit-learn`, `nltk`, `wordcloud`

**Installation rapide**â€¯:
```bash
pip install pandas numpy matplotlib seaborn scikit-learn nltk wordcloud
```

**Pour NLTK, tÃ©lÃ©charger les ressources nÃ©cessaires**â€¯:
```python
import nltk
nltk.download('stopwords')
nltk.download('wordnet')
nltk.download('omw-1.4')
```

---

## ğŸš€ Reproduire lâ€™expÃ©rience

1. **TÃ©lÃ©charge le dataset** sur Kaggle et place-le dans `data/sentiment_analysis.csv`
2. **Ouvre les notebooks dans lâ€™ordre**â€¯:
   - `notebooks/1_data_exploration.ipynb`
   - `notebooks/2_data_preprocessing.ipynb`
   - `notebooks/3_model_training_evaluation.ipynb`
3. **ExÃ©cute chaque cellule** pour suivre le pipeline complet
4. **Les modÃ¨les et vectoriseurs** sont sauvegardÃ©s dans `models/` Ã  la fin du notebook 3

---

## ğŸ“Š RÃ©sultats attendus

- Visualisations dÃ©taillÃ©es sur la structure et la rÃ©partition des donnÃ©es
- Texte nettoyÃ©, vectorisÃ© et prÃªt pour la modÃ©lisation
- Comparatif objectif des modÃ¨les classiques
- SÃ©lection et justification argumentÃ©e du meilleur modÃ¨le
- PrÃªt pour une intÃ©gration (API, app web, etc.)

---

## âœï¸ Auteur

- [ThePerformer0](https://github.com/ThePerformer0)  
Projet dÃ©veloppÃ© dans lâ€™organisation **INFO-DECISIO** pour le cours dâ€™informatique dÃ©cisionnel.

---

## ğŸ™ Remarques & extensions possibles

- Ce projet constitue une base solide pour expÃ©rimenter avec des modÃ¨les avancÃ©s (Word Embeddings, deep learning, transformers, gestion du dÃ©sÃ©quilibre des classesâ€¦)
- Nâ€™hÃ©site pas Ã  cloner le repo, tester sur dâ€™autres jeux de donnÃ©es ou proposer des amÃ©liorations/pull requestsâ€¯!

---

**Bon apprentissage et bonne exploration du sentimentâ€¯!**
